
<p align="center">
  <img src="docs/assets/logo.svg" alt="WSAttention-Prostate Logo" width="560">
</p>

<p align="center">
  <a href="https://github.com/anirudhbalaraman/WSAttention-Prostate/actions"><img alt="Continuous Integration" src="https://github.com/anirudhbalaraman/WSAttention-Prostate/actions/workflows/ci.yaml/badge.svg"></a>
  <img src="https://img.shields.io/badge/python-3.9-blue?logo=python&logoColor=white" alt="Python 3.9">
  <img src="https://img.shields.io/badge/pytorch-2.5-ee4c2c?logo=pytorch&logoColor=white" alt="PyTorch 2.5">
  <img src="https://img.shields.io/badge/MONAI-1.4-3ddc84" alt="MONAI 1.4">
  <img src="https://img.shields.io/badge/license-Apache%202.0-green" alt="License">
  <a href="https://github.com/astral-sh/ruff">
  <img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json" alt="Code style: ruff">
  </a>
</p>

# Weakly Supervised Attention-Based Deep Learning for Prostate Cancer Characterization from Bi-Parametric Prostate MRI.
Predicts PI-RADS score and risk of clinically significant prostate cancer (csPCa) from T2-Weighted (T2W), Diffusion Weighted Imaging (DWI) and Apparent Diffusion Coefficient (ADC) sequences of bi-paramteric MRI (bpMRI).

## üöÄ Platform Access
Real-time inference via [GUI](https://huggingface.co/spaces/anirudh0410/Prostate-Inference)

## ‚≠ê Abstract

Deep learning methods used in medical AI‚Äîparticularly for csPCa prediction and PI-RADS classification‚Äîtypically rely on expert-annotated labels for training, which limits scalability to larger datasets and broader clinical adoption. To address this, we employ a two-stage multiple-instance learning (MIL) framework pretrained on scan-level PI-RADS annotations with attention-based weak supervision, guided by weak attention heatmaps automatically derived from ADC and DWI sequences. For downstream risk assessment, the PI-RADS classification head is replaced and fine-tuned on a substantially smaller dataset to predict csPCa risk. Careful preprocessing is applied to mitigate variability arising from cross-site MRI acquisition differences. For further details, please refer to our paper or visit the project website.

## Key Features

- ‚ö°**Automatic Attention Heatmaps** - Weak attention heatmaps generated automatically from DWI and ADC sequnces.
- üß†**Weakly-Supervised Attention** ‚Äî Heatmap-guided patch sampling and cosine-similarity attention loss, replace the need for voxel-level labels.
- üß©**3D Multiple Instance Learning** ‚Äî Extracts volumetric patches from bpMRI scans and aggregates them via transformer + attention pooling.
- üëÅÔ∏è**Two-stage pipeline** ‚Äî Visualise salient patches highlighting probable tumour regions.
- üßπ**Preprocessing** ‚Äî Preprocessing to minimize inter-center MRI acquisiton variability.
- üè•**End-to-end Pipeline** ‚Äî Open source, clinically viable complete pipeline. 


## Quick Start

```bash
git clone https://github.com/anirudhbalaraman/WSAttention-Prostate.git
cd WSAttention-Prostate
pip install -r requirements.txt
pytest tests/
```
### Model Download

```bash
MODELS_DIR="./models"
mkdir -p ./models
curl -L -o models/file1.pth https://huggingface.co/anirudh0410/WSAttention-Prostate/resolve/main/cspca_model.pth
curl -L -o models/file2.pth https://huggingface.co/anirudh0410/WSAttention-Prostate/resolve/main/pirads.pt
curl -L -o models/file3.pth https://huggingface.co/anirudh0410/WSAttention-Prostate/resolve/main/prostate_segmentation_model.pt
```

## Usage

### Preprocessing

```bash
python preprocess_main.py --config config/config_preprocess.yaml \
    --steps register_and_crop get_segmentation_mask histogram_match get_heatmap
```

### PI-RADS Training

```bash
python run_pirads.py --mode train --config config/config_pirads_train.yaml
```

### csPCa Training

```bash
python run_cspca.py --mode train --config config/config_cspca_train.yaml
```

### Inference

```bash
python run_pirads.py --mode test --config config/config_pirads_test.yaml --checkpoint <path>
python run_cspca.py --mode test --config config/config_cspca_test.yaml --checkpoint_cspca <path>
python run_inference.py --config config/config_preprocess.yaml
```

See the [full documentation](https://anirudhbalaraman.github.io/WSAttention-Prostate/) for detailed configuration options and data format requirements.

## Project Structure

```
WSAttention-Prostate/
‚îú‚îÄ‚îÄ run_pirads.py              # PI-RADS training/testing entry point
‚îú‚îÄ‚îÄ run_cspca.py               # csPCa training/testing entry point
‚îú‚îÄ‚îÄ run_inference.py           # Full inference pipeline
‚îú‚îÄ‚îÄ preprocess_main.py         # Preprocessing entry point
‚îú‚îÄ‚îÄ config/                    # YAML configuration files
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MIL.py             # MILModel_3D ‚Äî core MIL architecture
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ csPCa_model.py     # csPCa_Model + SimpleNN head
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py     # MONAI data pipeline
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ custom_transforms.py
‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_pirads.py    # PI-RADS training loop
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_cspca.py     # csPCa training loop
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/         # Registration, segmentation, heatmaps
‚îÇ   ‚îî‚îÄ‚îÄ utils.py               # Shared utilities and step validation
‚îú‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ dataset/                   # Reference images for histogram matching
‚îî‚îÄ‚îÄ models/                    # Downloaded checkpoints (not in repo)
```

## Architecture

Input MRI patches are processed independently through a 3D ResNet18 backbone, then aggregated via a transformer encoder and attention pooling:

```mermaid
flowchart TD
    A["Input [B, N, C, D, H, W]"] --> B["Reshape to [B*N, C, D, H, W]"]
    B --> C[ResNet18-3D Backbone]
    C --> D["Reshape to [B, N, 512]"]
    D --> E[Transformer Encoder\n4 layers, 8 heads]
    E --> F[Attention Pooling\n512 ‚Üí 2048 ‚Üí 1]
    F --> G["Weighted Sum [B, 512]"]
    G --> H["FC Head [B, num_classes]"]
```

For csPCa prediction, the backbone is frozen and a 3-layer MLP (`512 ‚Üí 256 ‚Üí 128 ‚Üí 1`) replaces the classification head.

